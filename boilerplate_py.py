# -*- coding: utf-8 -*-
"""boilerplate.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10zEAtuG_e1Zt79opimIwOJTDJnpr9p-P

-training loop
-optimizer
-scheduler
-model
"""

import torch.nn as nn
import torch

class Model(nn.Module):
  def __init__(self,*args,**kwargs):
    super().__init__(*args,**kwargs)
    self.optimizer = None
    self.scheduler = None
    self.train_loader = None
    self.valid_loader = None

  def forward(self,*args,**kwargs):
    super().forward(*args,**kwargs)


  def fetch_optimizer(self,*args,**kwargs):
    return

  def train_one_step(self,data,device):
    self.optimizer.zero_grad()
    
    for k,v in data.items():
      data[k] = v.to(device)
    
    _,loss = self(**data)
    loss.backward()
    self.optimizer.step()
    self.scheduler.step()

    return loss

  def train_one_epoch(self,data_loader,device):
    self.train()
    epoch_loss = 0
    for data in data_loader:
      loss = self.train_one_step(data,device)
      epoch_loss += loss
    return epoch_loss/len(data_loader)

 
  
  def fit(self,train_dataset,batch_size,epochs,device):
    if self.train_loader is None:
      self.train_loader = torch.utils.data.DataLoader(
          train_dataset,
          batch_size = batch_size,
          shuffle = True
      )
    
    if next(self.parameters()).device() != device:
      self.to(device)
    
    
    self.optimizer = self.fetch_optimizer()
    self.scheduler = self.fetch_scheduler()
    
    for _ in range(epochs):
      train_loss = self.train_one_epoch(self.train_loader,device)

class MyModel(Model):
  def __init__(self,num_classes):
    #Define Multiple N/W Layers
    self.out = nn.Linear(128,num_classes)
  
  def loss(self,outputs,targets):
    if targets is None:
      return None
    return nn.BCEWithLogitsLoss()(outputs,targets)


  def fetch_scheduler(self):
    scheduler = torch.optim.lr_scheduler().StepLR(self.optimizer)
    return scheduler

  def fetch_optimizer(self):
    optim = torch.optim.Adam(self.parameters())
    return optim



  def forward(self,x,targets = None):
    #x = self.nwrk(x)
    #x = self.nwrk2(x)
    #out = self.nwrk3(x)
    loss = self.loss(out,targets)
    return out,loss

m = MyModel()
m.fit(train_dataset,batch_size = 16,device = "cuda")