{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CustomDatasetforImages.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnsmSZ-lQe3K"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from skimage import io"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ScmzwNjX_KZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader \n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDKRki9QRSuW"
      },
      "source": [
        "class image_dataset(Dataset):\n",
        "  def __init__(self,csv_file,root_dir,transform = None):\n",
        "    self.annotations = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    y_label = int(self.annotations.iloc[index,1])\n",
        "    img_path = os.path.join(self.root_dir+\"/{}\".format(y_label),self.annotations.iloc[index,0])\n",
        "    image = io.imread(img_path)\n",
        "    y_label = torch.tensor(y_label)\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "      p = transforms.Compose([transforms.Scale((256,256))])\n",
        "      image = p(image)\n",
        "      \n",
        "    return (image,y_label)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE8PZMLBT3ND",
        "outputId": "83387610-0903-4839-d628-a7b9a79fb88a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdW-bvxBZPt6"
      },
      "source": [
        "!pip install --upgrade kaggle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uShQLaUdSvLS"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "def setup(api):\n",
        "  import shutil\n",
        "  ss = api.split()\n",
        "  folder = ss[-1]\n",
        "  os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle/\"+folder\n",
        "  print(folder)\n",
        "  %cd /content/gdrive/My Drive/Kaggle/\n",
        "  !mkdir $folder\n",
        "  shutil.copy2(\"kaggle.json\",\"./\"+folder+\"/kaggle.json\")\n",
        "  %cd $folder\n",
        "  !kaggle competitions download -c $folder\n",
        "\n",
        "setup(\"kaggle competitions download -c human-age-recognition\")\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8aO8hGjb7VK"
      },
      "source": [
        "!unzip human-age-recognition.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfdgvbY8XQNT"
      },
      "source": [
        "df = image_dataset(\"train.csv\",root_dir=\"./train/train\",transform=transforms.ToTensor())"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amTHOQ21dg4A"
      },
      "source": [
        "train_set,test_set = torch.utils.data.random_split(dataset=df,lengths=[10000,df.__len__()-10000])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ubOvY4XespM"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_set,batch_size=64,shuffle=True)\n",
        "test_loader = DataLoader(dataset = test_set,batch_size = 64,shuffle = True)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaWCrmqKa5dh"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self,in_channels = 1,num_classes = 10):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels= in_channels,out_channels = 8,kernel_size =(3,3),stride = (1,1),padding = (1,1))\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "    self.conv2 = nn.Conv2d(in_channels= 8,out_channels = 16,kernel_size =(3,3),stride = (1,1),padding = (1,1))\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "    self.fc1 = nn.Linear(16*64*64,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    x = self.fc1(x)\n",
        "    return x"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeccuX4nfGBf"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device\n",
        "\n",
        "in_channels = 3\n",
        "num_classes = 7\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 4"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO12ZbN4fAgt"
      },
      "source": [
        "model = CNN(in_channels,num_classes).to(device = device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = learning_rate)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvMtRqt3fDZV"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(data,targets) in enumerate(train_loader):\n",
        "    #get data to cuda if possible \n",
        "    data = data.cuda()\n",
        "    targets = targets.cuda()\n",
        "\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores,targets)\n",
        "\n",
        "    #backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "    #gradient_descent or adam-step\n",
        "    optimizer.step()\n",
        "\n",
        "# Check the accuracy for the training step\n",
        "def check_accuracy(loader,model):\n",
        "  if loader.dataset.train:\n",
        "    print(\"Checking accuracy on training data\")\n",
        "  else:\n",
        "    print(\"Checking accuracy on test data\")\n",
        "\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x,y in loader:\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "\n",
        "      scores = model(x)\n",
        "      _,predictions = scores.max(1)\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "    print(f' Got {num_correct}/{num_samples} with accuracy ={float(num_correct)/float(num_samples)*100:.2f} ')\n",
        "    model.train()\n",
        "\n",
        "check_accuracy(train_loader,model)\n",
        "check_accuracy(test_loader,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bReBHxKgE9A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}